{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arohi-jd/Activ8/blob/main/Question_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3da299b1",
      "metadata": {
        "id": "3da299b1"
      },
      "source": [
        "# Decision Tree Regression - Taxi Fare Prediction\n",
        "\n",
        "- Dataset: NYC Yellow Taxi Trip Data (March 2016)\n",
        "\n",
        "### Exercise: Build a Decision Tree Model\n",
        "\n",
        "In this exercise, you will build a Decision Tree Regressor to predict taxi fare amounts. Fill in the blanks to complete the code."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7c57ef0",
      "metadata": {
        "id": "f7c57ef0"
      },
      "source": [
        "# Dataset URL - https://www.kaggle.com/datasets/elemento/nyc-yellow-taxi-trip-data?select=yellow_tripdata_2016-03.csv\n",
        "\n",
        "\n",
        "# What Uber uses for Dynamic Pricing\n",
        "- https://www.uber.com/blog/research/dynamic-pricing-and-matching-in-ride-hailing-platforms/\n",
        "- https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3258234&uclick_id=3356e8d9-7bcd-442d-967c-86ae22ef8e57"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f376639",
      "metadata": {
        "id": "3f376639"
      },
      "source": [
        "* **Import Libraries:** This cell imports the necessary libraries for our model - `pandas` for data manipulation, and `sklearn` for machine learning.\n",
        "\n",
        "**Hints:**\n",
        "- Import `train_test_split` from sklearn's model_selection module\n",
        "- Import `DecisionTreeRegressor` from sklearn's tree module\n",
        "- Import evaluation metrics from sklearn's metrics module\n",
        "\n",
        "**Documentation:**\n",
        "- [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
        "- [DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)\n",
        "- [mean_absolute_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html)\n",
        "- [r2_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "08VSQKaS--G9"
      },
      "id": "08VSQKaS--G9",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d96b820",
      "metadata": {
        "id": "4d96b820"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import ______\n",
        "from sklearn.tree import ______\n",
        "from sklearn.metrics import mean_absolute_error, r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99dcee0c",
      "metadata": {
        "id": "99dcee0c"
      },
      "source": [
        "* **Load Dataset & Extract Features:** This cell loads the taxi trip data CSV file, removes duplicate rows, fills missing values, and extracts datetime features.\n",
        "\n",
        "**Hints:**\n",
        "- Use `pd.read_csv()` to load CSV files\n",
        "- Use `.drop_duplicates()` to remove duplicate rows\n",
        "- Use `.fillna()` to fill missing values\n",
        "- Use `pd.to_datetime()` to parse datetime strings\n",
        "- Extract `.dt.hour`, `.dt.dayofweek`, `.dt.month` from datetime\n",
        "\n",
        "**Documentation:**\n",
        "- [pd.read_csv](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)\n",
        "- [DataFrame.drop_duplicates](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html)\n",
        "- [DataFrame.fillna](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html)\n",
        "- [pd.to_datetime](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html)\n",
        "- [DatetimeIndex.hour](https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.hour.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6980e788",
      "metadata": {
        "id": "6980e788"
      },
      "outputs": [],
      "source": [
        "df = pd.______(______)\n",
        "df = df.______()\n",
        "df = df.______(0)\n",
        "\n",
        "df['pickup_datetime'] = pd.______(df['______'])\n",
        "\n",
        "df['pickup_hour'] = df['pickup_datetime'].dt.______\n",
        "df['pickup_day'] = df['pickup_datetime'].dt.______\n",
        "df['pickup_month'] = df['pickup_datetime'].dt.______\n",
        "\n",
        "print(f\"Samples: {len(df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fea9970e",
      "metadata": {
        "id": "fea9970e"
      },
      "source": [
        "## Quick Data Insights\n",
        "\n",
        "* **Explore Data:** This cell displays basic statistics about fare amounts and trip distances.\n",
        "\n",
        "**Hints:**\n",
        "- Use `.min()`, `.max()`, `.mean()` for statistics\n",
        "- Use `.nunique()` to count unique values\n",
        "\n",
        "**Documentation:**\n",
        "- [Series.min](https://pandas.pydata.org/docs/reference/api/pandas.Series.min.html)\n",
        "- [Series.max](https://pandas.pydata.org/docs/reference/api/pandas.Series.max.html)\n",
        "- [Series.mean](https://pandas.pydata.org/docs/reference/api/pandas.Series.mean.html)\n",
        "- [DataFrame.head](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a62d4a26",
      "metadata": {
        "id": "a62d4a26"
      },
      "outputs": [],
      "source": [
        "# Calculate and display basic statistics for the 'fare_amount' column\n",
        "print(\"Fare Amount Stats:\")\n",
        "print(f\"   Min: ${df['fare_amount'].______():.2f}\")\n",
        "print(f\"   Max: ${df['fare_amount'].______():.2f}\")\n",
        "print(f\"   Avg: ${df['fare_amount'].______():.2f}\")\n",
        "\n",
        "# Calculate and display basic statistics for the 'trip_distance' column\n",
        "print(f\"\\nTrip Distance Stats:\")\n",
        "print(f\"   Min: {df['trip_distance'].min():.2f} miles\")\n",
        "print(f\"   Max: {df['trip_distance'].max():.2f} miles\")\n",
        "print(f\"   Avg: {df['trip_distance'].mean():.2f} miles\")\n",
        "\n",
        "# Count and display the number of unique vendors\n",
        "print(f\"\\nUnique Vendors: {df['VendorID'].______()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85d87fb8",
      "metadata": {
        "id": "85d87fb8"
      },
      "source": [
        "* **Payment Type Analysis:** This cell shows the distribution of payment types.\n",
        "\n",
        "**Hints:**\n",
        "- Use `.value_counts()` to count occurrences\n",
        "\n",
        "**Documentation:**\n",
        "- [Series.value_counts](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bb73266",
      "metadata": {
        "id": "1bb73266"
      },
      "outputs": [],
      "source": [
        "# Analyze the distribution of payment types in the dataset\n",
        "# Payment types: 1=Credit card, 2=Cash, 3=No charge, 4=Dispute\n",
        "print(\"Payment Type Distribution:\")\n",
        "print(df['payment_type'].______().head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "800c2fd5",
      "metadata": {
        "id": "800c2fd5"
      },
      "source": [
        "## Data Cleaning\n",
        "\n",
        "* **Filter Invalid Data:** This cell removes rows with invalid fare amounts or trip distances.\n",
        "\n",
        "**Hints:**\n",
        "- Use boolean indexing to filter rows\n",
        "- Filter out negative fares and zero/negative distances\n",
        "\n",
        "**Documentation:**\n",
        "- [DataFrame indexing](https://pandas.pydata.org/docs/user_guide/indexing.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d23cd092",
      "metadata": {
        "id": "d23cd092"
      },
      "outputs": [],
      "source": [
        "# Remove rows with invalid fare amounts and trip distances\n",
        "original_len = len(df)  # Store the original number of rows in the dataset\n",
        "\n",
        "# Filter out rows with fare amounts less than or equal to 0 or greater than 200\n",
        "df = df[(df[______] ______ 0) & (df[________] ______ 200)]\n",
        "\n",
        "# Filter out rows with trip distances less than or equal to 0 or greater than 100\n",
        "df = df[(df['trip_distance'] > 0) & (df['trip_distance'] < 100)]\n",
        "\n",
        "# Print the number of removed and remaining records\n",
        "print(f\"Removed {original_len - len(df)} invalid records\")\n",
        "print(f\"Remaining samples: {len(df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "518a1bd7",
      "metadata": {
        "id": "518a1bd7"
      },
      "source": [
        "## Feature Selection and Model Training\n",
        "\n",
        "* **Select Features:** This cell selects relevant features for predicting fare amount, including temporal and location features.\n",
        "\n",
        "**Hints:**\n",
        "- Select numeric features that influence fare: trip distance, passenger count, rate code, payment type\n",
        "- Include datetime features: pickup hour, day of week, month\n",
        "- Include location features: pickup/dropoff coordinates\n",
        "- Use double brackets `df[[...]]` to select multiple columns\n",
        "\n",
        "**Documentation:**\n",
        "- [DataFrame column selection](https://pandas.pydata.org/docs/user_guide/indexing.html#basics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6394a36",
      "metadata": {
        "id": "e6394a36"
      },
      "outputs": [],
      "source": [
        "X = df[[______, ______, ______, ______,\n",
        "        ______, ______, ______,\n",
        "        ______, ______, ______, ______]]\n",
        "\n",
        "y = df[______]\n",
        "\n",
        "print(f\"Features shape: {X.______}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "print(f\"Features to use: trip_distance, passenger_count, RatecodeID, payment_type, pickup_hour, pickup_day, pickup_month, pickup_longitude, pickup_latitude, dropoff_longitude, dropoff_latitude\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40d02033",
      "metadata": {
        "id": "40d02033"
      },
      "source": [
        "* **Train-Test Split:** This cell splits the data into training and testing sets.\n",
        "\n",
        "**Hints:**\n",
        "- Use `train_test_split()` function\n",
        "- Set `test_size=0.2` for 80-20 split\n",
        "- Set `random_state=42` for reproducibility\n",
        "\n",
        "**Documentation:**\n",
        "- [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05491109",
      "metadata": {
        "id": "05491109"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and testing sets\n",
        "# Use an 80-20 split and set a random state for reproducibility\n",
        "X_train, X_test, y_train, y_test = ______(X, y, test_size=______, random_state=42)\n",
        "\n",
        "# Print the number of samples in the training and testing sets\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Testing samples: {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b57c118",
      "metadata": {
        "id": "2b57c118"
      },
      "source": [
        "* **Train Decision Tree:** This cell creates and trains the Decision Tree Regressor model.\n",
        "\n",
        "**Hints:**\n",
        "- Create model with `max_depth=10` to prevent overfitting\n",
        "- Use `.fit()` method to train the model\n",
        "\n",
        "**Documentation:**\n",
        "- [DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)\n",
        "- [DecisionTreeRegressor.fit](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor.fit)\n",
        "- [DecisionTreeRegressor.predict](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor.predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eb5a630",
      "metadata": {
        "id": "6eb5a630"
      },
      "outputs": [],
      "source": [
        "# Train a Decision Tree Regressor model\n",
        "# Initialize the model with a maximum depth of 10 to prevent overfitting\n",
        "model = ______(max_depth=______, random_state=42)\n",
        "\n",
        "# Train the model using the training data\n",
        "model.______(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.______(X_test)\n",
        "\n",
        "# Print a confirmation message\n",
        "print(\"Model trained!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd5c6407",
      "metadata": {
        "id": "bd5c6407"
      },
      "source": [
        "* **Evaluate Model:** This cell calculates and displays the model's performance metrics.\n",
        "\n",
        "**Hints:**\n",
        "- MAE (Mean Absolute Error) measures average prediction error\n",
        "- R2 Score measures how well the model explains variance (1.0 is perfect)\n",
        "\n",
        "**Documentation:**\n",
        "- [mean_absolute_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html)\n",
        "- [r2_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c88dc7e",
      "metadata": {
        "id": "7c88dc7e"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model's performance using MAE and R² metrics\n",
        "# Calculate the Mean Absolute Error (MAE) between actual and predicted values\n",
        "mae = ______(y_test, y_pred)\n",
        "\n",
        "# Calculate the R² score to measure the model's variance explanation\n",
        "r2 = ______(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"MAE: ${mae:.2f}\")\n",
        "print(f\"R²:  {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61ddb0a9",
      "metadata": {
        "id": "61ddb0a9"
      },
      "source": [
        "* **Make Prediction:** This cell demonstrates how to make a prediction for a new sample.\n",
        "\n",
        "**Hints:**\n",
        "- Create a DataFrame with the same columns as training data\n",
        "- Use `model.predict()` to make predictions\n",
        "\n",
        "**Documentation:**\n",
        "- [pd.DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)\n",
        "- [DecisionTreeRegressor.predict](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor.predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4aab307",
      "metadata": {
        "id": "a4aab307"
      },
      "outputs": [],
      "source": [
        "sample = pd.______(\n",
        "    {\n",
        "        'trip_distance': [5.0],\n",
        "        'passenger_count': [2],\n",
        "        'RatecodeID': [1],\n",
        "        'payment_type': [1],\n",
        "        'pickup_hour': [18],\n",
        "        'pickup_day': [4],\n",
        "        'pickup_month': [3],\n",
        "        'pickup_longitude': [-73.98],\n",
        "        'pickup_latitude': [40.75],\n",
        "        'dropoff_longitude': [-73.95],\n",
        "        'dropoff_latitude': [40.78]\n",
        "    }\n",
        ")\n",
        "prediction = model.______(sample)[0]\n",
        "print(f\"Predicted fare for 5-mile trip: ${prediction:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae1474a3",
      "metadata": {
        "id": "ae1474a3"
      },
      "source": [
        "## Feature Importance\n",
        "\n",
        "* **Analyze Feature Importance:** This cell shows which features are most important for predicting fare.\n",
        "\n",
        "**Hints:**\n",
        "- Use `model.feature_importances_` to get importance scores\n",
        "- Higher values indicate more important features\n",
        "\n",
        "**Documentation:**\n",
        "- [DecisionTreeRegressor.feature_importances_](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35b86c68",
      "metadata": {
        "id": "35b86c68"
      },
      "outputs": [],
      "source": [
        "# Analyze the importance of each feature in the Decision Tree model\n",
        "# Get the list of feature names from the dataset\n",
        "feature_names = X.columns.tolist()\n",
        "\n",
        "# Retrieve the feature importance scores from the trained model\n",
        "importances = model.______\n",
        "\n",
        "# Print the importance of each feature\n",
        "print(\"Feature Importances:\")\n",
        "for name, importance in zip(feature_names, importances):\n",
        "    print(f\"   {name}: {importance:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "800bc75f",
      "metadata": {
        "id": "800bc75f"
      },
      "source": [
        "# How is Dynamic Pricing Implemented in Real Taxi Services?\n",
        "\n",
        "## Real-world taxi fare prediction systems consider many more factors:\n",
        "- **Time of day** - Rush hour surge pricing\n",
        "- **Weather conditions** - Rain/snow increases demand\n",
        "- **Special events** - Concerts, sports games\n",
        "- **Real-time demand** - Supply and demand in the area\n",
        "- **Traffic conditions** - Estimated time of arrival\n",
        "\n",
        "## Here is an article about how Uber implements dynamic pricing:\n",
        "https://www.uber.com/us/en/marketplace/pricing/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afc07f44",
      "metadata": {
        "id": "afc07f44"
      },
      "source": [
        "# PyTorch Neural Network - Taxi Fare Prediction\n",
        "\n",
        "### Exercise: Build a Neural Network with PyTorch\n",
        "\n",
        "In this exercise, you will build a simple Neural Network using PyTorch to predict taxi fare amounts. Fill in the blanks to complete the code."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe5a36d0",
      "metadata": {
        "id": "fe5a36d0"
      },
      "source": [
        "* **Import Libraries:** This cell imports the necessary libraries including PyTorch for deep learning.\n",
        "\n",
        "**Hints:**\n",
        "- Import `torch.nn` as `nn` for neural network layers\n",
        "- Import `torch.optim` for optimizers\n",
        "- Import `DataLoader` and `TensorDataset` from torch.utils.data\n",
        "\n",
        "**Documentation:**\n",
        "- [torch.nn](https://pytorch.org/docs/stable/nn.html)\n",
        "- [torch.optim](https://pytorch.org/docs/stable/optim.html)\n",
        "- [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)\n",
        "- [TensorDataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "985efbb8",
      "metadata": {
        "id": "985efbb8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import torch\n",
        "import torch.nn as ______\n",
        "import torch.optim as ______\n",
        "from torch.utils.data import ______, ______\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a086e4fb",
      "metadata": {
        "id": "a086e4fb"
      },
      "source": [
        "* **Load and Prepare Data:** This cell loads the dataset, cleans it, extracts datetime features, and selects features including temporal and location data.\n",
        "\n",
        "**Hints:**\n",
        "- Use `.dropna()` to remove missing values\n",
        "- Use `.drop_duplicates()` to remove duplicates\n",
        "- Filter invalid fare and distance values\n",
        "- Extract datetime features (hour, day of week, month)\n",
        "- Include location coordinates in feature selection\n",
        "\n",
        "**Documentation:**\n",
        "- [pd.read_csv](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)\n",
        "- [DataFrame.dropna](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html)\n",
        "- [pd.to_datetime](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d75ae17",
      "metadata": {
        "id": "3d75ae17"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('yellow_tripdata_2016-03.csv').______().______()\n",
        "print(f\"Samples after cleaning: {len(df)}\")\n",
        "\n",
        "df = df[(df['fare_amount'] > 0) & (df['fare_amount'] < 200)]\n",
        "df = df[(df['trip_distance'] > 0) & (df['trip_distance'] < 100)]\n",
        "\n",
        "df['pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
        "df['pickup_hour'] = df['pickup_datetime'].dt.hour\n",
        "df['pickup_day'] = df['pickup_datetime'].dt.dayofweek\n",
        "df['pickup_month'] = df['pickup_datetime'].dt.month\n",
        "\n",
        "X = df[['trip_distance', 'passenger_count', 'RatecodeID', 'payment_type',\n",
        "        'pickup_hour', 'pickup_day', 'pickup_month',\n",
        "        'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']]\n",
        "y = df['fare_amount']\n",
        "\n",
        "print(f\"Features: {X.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7638852",
      "metadata": {
        "id": "a7638852"
      },
      "source": [
        "* **Scale and Convert to Tensors:** This cell scales the features using StandardScaler and converts data to PyTorch tensors.\n",
        "\n",
        "**Hints:**\n",
        "- Use `scaler.fit_transform()` for training data\n",
        "- Use `scaler.transform()` for test data (no fitting!)\n",
        "- Use `torch.FloatTensor()` to create tensors\n",
        "\n",
        "**Documentation:**\n",
        "- [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
        "- [StandardScaler.fit_transform](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.fit_transform)\n",
        "- [torch.FloatTensor](https://pytorch.org/docs/stable/tensors.html)\n",
        "- [Tensor.reshape](https://pytorch.org/docs/stable/generated/torch.Tensor.reshape.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6d6ce16",
      "metadata": {
        "id": "b6d6ce16"
      },
      "outputs": [],
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.______(X_train)\n",
        "X_test_scaled = scaler.______(X_test)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.______(X_train_scaled)\n",
        "y_train_tensor = torch.FloatTensor(y_train.values).______(______, ______)\n",
        "X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
        "y_test_tensor = torch.FloatTensor(y_test.values).reshape(-1, 1)\n",
        "\n",
        "print(f\"Train: {X_train_tensor.shape[0]} | Test: {X_test_tensor.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d390081",
      "metadata": {
        "id": "4d390081"
      },
      "source": [
        "## Define Neural Network\n",
        "\n",
        "* **Create Model Class:** This cell defines the neural network architecture with 2 hidden layers.\n",
        "\n",
        "**Hints:**\n",
        "- Use `nn.Linear(in_features, out_features)` for fully connected layers\n",
        "- Use `nn.ReLU()` or `nn.Sigmoid()` for activation functions\n",
        "- The network structure is: Input -> 64 neurons -> 32 neurons -> 1 output\n",
        "\n",
        "**Documentation:**\n",
        "- [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)\n",
        "- [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
        "- [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)\n",
        "- [nn.Sigmoid](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca1076c0",
      "metadata": {
        "id": "ca1076c0"
      },
      "outputs": [],
      "source": [
        "# Simple Neural Network\n",
        "class TaxiFareNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(TaxiFareNN, self).__init__()\n",
        "        self.fc1 = nn.______(input_size, 64)\n",
        "        self.fc2 = nn.Linear(64, ______)\n",
        "        self.fc3 = nn.Linear(32, ______)\n",
        "        self.activation = nn.______()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.______(x))\n",
        "        x = self.activation(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model\n",
        "input_size = X_train_tensor.shape[1]\n",
        "model = ______(input_size)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1daff77",
      "metadata": {
        "id": "a1daff77"
      },
      "source": [
        "## Train the Model\n",
        "\n",
        "* **Training Loop:** This cell sets up the loss function, optimizer, and runs the training loop.\n",
        "\n",
        "**Hints:**\n",
        "- Use `nn.MSELoss()` for regression problems\n",
        "- Use `optim.Adam()` as the optimizer\n",
        "- Call `optimizer.zero_grad()` before each backward pass\n",
        "- Call `loss.backward()` to compute gradients\n",
        "- Call `optimizer.step()` to update weights\n",
        "\n",
        "**Documentation:**\n",
        "- [nn.MSELoss](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html)\n",
        "- [optim.Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html)\n",
        "- [optimizer.zero_grad](https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html)\n",
        "- [Tensor.backward](https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html)\n",
        "- [optimizer.step](https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.step.html)\n",
        "- [model.train](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb7e2ff4",
      "metadata": {
        "id": "bb7e2ff4"
      },
      "outputs": [],
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.______()\n",
        "optimizer = optim.______(model.parameters(), lr=0.001)\n",
        "\n",
        "# Create DataLoader\n",
        "epochs = 100\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=________)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.______()\n",
        "    epoch_loss = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        optimizer.______()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.______()\n",
        "        optimizer.______()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss/len(train_loader):.4f}\")\n",
        "\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de139e8f",
      "metadata": {
        "id": "de139e8f"
      },
      "source": [
        "## Evaluate Model\n",
        "\n",
        "* **Test the Model:** This cell evaluates the model on the test set.\n",
        "\n",
        "**Hints:**\n",
        "- Use `model.eval()` to set evaluation mode\n",
        "- Use `torch.no_grad()` context to disable gradient computation\n",
        "- Use `.numpy()` to convert tensor to numpy array\n",
        "\n",
        "**Documentation:**\n",
        "- [model.eval](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.eval)\n",
        "- [torch.no_grad](https://pytorch.org/docs/stable/generated/torch.no_grad.html)\n",
        "- [Tensor.numpy](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e91e8a7b",
      "metadata": {
        "id": "e91e8a7b"
      },
      "outputs": [],
      "source": [
        "# Evaluate on test set\n",
        "model.______()\n",
        "with torch.______():\n",
        "    y_pred = model(X_test_tensor).______()\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"PyTorch Neural Network Results:\")\n",
        "print(f\"   MAE: ${mae:.2f}\")\n",
        "print(f\"   R2:  {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c36c4cd",
      "metadata": {
        "id": "1c36c4cd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}